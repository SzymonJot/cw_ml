---
title: "projekt_ML_3"
author: "Szymon Jarmołowski"
format: 
  html:
    self-contained: true
    embedded-resources: true
    toc: true
    toc-depth: 4
    toc-location: right
    toc-title: "Spis treści"
    number-sections: true
    number-depth: 4
    code-fold: show
    code-summary: "Show the code"
    code-tools: true
    code-block-bg: true
    code-block-border-left: "black"
    code-line-numbers: false
    code-copy: true
    html-math-method: katex
    smooth-scroll: true
    anchor-sections: true
    link-external-icon: true
    link-external-newwindow: true
---

# Klasyfikacja poziomu ozonu

## Import bibliotek
```{r}
#| warning: false
library(tidymodels) 
library(skimr) 
library(GGally) 
library(openair)
library(ggpubr)
library(corrplot)
library(lubridate)
library(car)
library(dplyr)
library(workflows)
library(e1071)
library(ranger)
library(yardstick)
tidymodels_prefer()

```

## Eksploracja danych

```{r}
air <- mydata |> selectByDate(year = 2002) 
air |> skim()
```
Wstępna analiza danych pokazuje, że niemal wszystkie zmienne posiadają braki, przy czym najwięcej brakujących obserwacji dotyczy pyłów PM2.5 (kompletność na poziomie 93%). Kluczową cechą charakterystyczną dla większości zanieczyszczeń, takich jak ozon (o3), pyły (pm10), tlenki azotu (nox) i dwutlenek siarki (so2), jest ich silnie prawoskośny rozkład. Oznacza to, że ich stężenia są zazwyczaj niskie, ale występują rzadkie epizody o ekstremalnie wysokich wartościach.


Usunięcie obserwacji z brakami danych
```{r}
air <- air |> na.omit()
```




```{r}
# wykres regresji liniowej, do sprawdzenia danych 
set.seed(222)
air[sample(1:nrow(air), size = 300, replace = F),] |> 
  select(nox, no2) |> 
  ggplot(aes(nox, no2)) +
  geom_point() +
  geom_smooth(method = "lm", se = T, formula = y ~ x) + 
  stat_cor(label.x = 10, label.y = 80) + 
  stat_regline_equation(label.x = 10, label.y = 82) +
  theme_bw()
```

```{r}
air |>    
  ggplot(aes(date, o3)) +     
  geom_line() +     
  theme_bw()
```

```{r}
air |> 
  pull(o3) |> 
  range()  
```

```{r}
air <-
  air |>
  mutate(ozone = cut(
    o3,
    breaks = c(-0.1, 10, 53),
    labels = c("Niskie", "Wysokie")
  ))
```

```{r}
air |> count(ozone)
```

```{r}
head(air)
```

```{r}

numeric_cols <- air |> select(where(is.numeric))
cor_matrix <- cor(numeric_cols)
corrplot(cor_matrix, method = "color", order = "hclust",
         addCoef.col = "black", tl.col = "black", tl.srt = 45, number.cex = 0.6,
         title = "Macierz korelacji zmiennych numerycznych", mar = c(0, 0, 2, 0))


```

Zmienna wd (wind direction) nie wykazuje korelacji. Nie zostanie włączona do modelu. NO2 jest zbyt mocno skorelowana z nox, co spowoduje problem współliniowości. Tlenek azotu (NOx) to zbiorcza nazwa związków z których najważniejsze to tlenek azotu (NO) i dwutlenek azotu (NO2). NO2 zostanie usunięty, ponieważ NOx zawiera w sobie infromacje na temat NO2 oraz bardziej koreluje z stężeniem ozonu.

```{r}
set.seed(222)
data_split <- initial_split(data = air, prop = 3/4, strata = ozone)
train_data <- training(data_split)
test_data <-  testing(data_split)
```

```{r}
numeric_cols <- air |> select(where(is.numeric))

# Oblicz skośność dla każdej kolumny
skosnosc <- sapply(numeric_cols, skewness, na.rm = TRUE)

# Wyświetl wyniki
print(skosnosc)

```

Ze względu na wysoką skośność zmiennych pm10, so2 oraz pm25 zostanie zastosowane przekształcenie YeoJohnson, ponieważ istnieją obserwacje z wartością 0.

```{r}
summary(air[, c("pm10", "so2", "pm25")])

```

```{r}

pt <- powerTransform(cbind(pm10, so2, pm25) ~ 1, data = air, family = "yjPower")
summary(pt)

air$pm10 <- yjPower(air$pm10, pt$lambda[1])
air$so2 <- yjPower(air$so2, pt$lambda[2])
air$pm25 <- yjPower(air$pm25, pt$lambda[3])

```

```{r}
numeric_cols <- air |> select(where(is.numeric))

# Oblicz skośność dla każdej kolumny
skosnosc <- sapply(numeric_cols, skewness, na.rm = TRUE)

# Wyświetl wyniki
print(skosnosc)
```

## Budowa przepisu oraz modelu
```{r}
rec <- recipe(ozone ~ ., data = train_data) |> 
  step_YeoJohnson(all_of(c("pm10", "so2", "pm25"))) |> 
  step_date(date, features = "month") |> 
  step_time(date, features = "hour") |> 
  step_mutate(date_month = as.numeric(date_month)) |> 
  step_mutate(
    season = case_when(
      date_month %in% c(12, 1, 2)  ~ "Zima",
      date_month %in% c(3, 4, 5)   ~ "Wiosna",
      date_month %in% c(6, 7, 8)   ~ "Lato",
      date_month %in% c(9, 10, 11) ~ "Jesien"
    )
  ) |> 
  step_mutate(season = as.factor(season)) |> 
  step_mutate(
    pora_dnia = case_when(
      date_hour >= 6 & date_hour < 22 ~ "Dzień",
      TRUE                             ~ "Noc"
    )
  ) |> 
  step_rm(date_month, date_hour, no2, wd, o3, date, co,so2) |> 
  step_mutate(pora_dnia = as.factor(pora_dnia)) |> 
  step_dummy(all_nominal(), -all_outcomes())

```

```{r}
rec_prep <- prep(rec, training = train_data)
air_transformed <- bake(rec_prep, new_data = NULL)
head(air_transformed)

```

```{r}
log_reg_spec <- logistic_reg() |> 
  set_engine("glm") |> 
  set_mode("classification")

rf_spec <- rand_forest(trees = 500, mtry = tune(), min_n = tune()) |> 
  set_engine("ranger", importance = "impurity") |> 
  set_mode("classification")
```


```{r}
set.seed(123)

# 1. V-krotna Kros Walidacja (5 CV)
cv_folds <- vfold_cv(train_data, v = 5, strata = ozone)

# 2. Bootstrap resampling
bootstrap_folds <- bootstraps(train_data, times = 100, strata = ozone)
```

```{r}
log_wf <- workflow() |> 
  add_model(log_reg_spec) |> 
  add_recipe(rec)
```

```{r}
# 1. CV
log_cv_results <- fit_resamples(
  log_wf,
  resamples = cv_folds,
  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)
)

log_cv_metrics <- collect_metrics(log_cv_results)
print(log_cv_metrics)

# 2. Bootstrap)
log_bootstrap_results <- fit_resamples(
  log_wf,
  resamples = bootstrap_folds,
  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)
)

log_bootstrap_metrics <- collect_metrics(log_bootstrap_results)
print(log_bootstrap_metrics)

```

## Las losowy
```{r}
rf_wf <- workflow() |> 
  add_model(rf_spec) |> 
  add_recipe(rec)
```


```{r}
rf_grid <- grid_regular(
  mtry(range = c(2, 8)),
  min_n(range = c(2, 20)),
  levels = 3
)

```

```{r}
rf_cv_results <- tune_grid(
  rf_wf,
  resamples = cv_folds,
  grid = rf_grid,
  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)
)
best_rf_params <- select_best(rf_cv_results, metric = "accuracy")
final_rf_wf <- finalize_workflow(rf_wf, best_rf_params)
```

```{r}
rf_cv_final <- fit_resamples(
  final_rf_wf,
  resamples = cv_folds,
  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)
)
rf_cv_metrics <- collect_metrics(rf_cv_final)
print(rf_cv_metrics)

```


```{r}
rf_bootstrap_results <- fit_resamples(
  final_rf_wf,
  resamples = bootstrap_folds,
  metrics = metric_set(accuracy, roc_auc, sensitivity, specificity)
)

rf_bootstrap_metrics <- collect_metrics(rf_bootstrap_results)
print(rf_bootstrap_metrics)

```

## Wnioski

Metryki wydajności obu metod są bardzo podobne, co świadczy o tym, że obie metod zwracają podobne wyniki. Walidacja krzyżowa oraz bootstrapping pozwolił uzyskać stabilne oceny modelu
